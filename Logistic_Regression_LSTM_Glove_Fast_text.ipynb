{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Logistic_Regression_LSTM_Glove_Fast_text_(2).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oni-h-tGakSp"
      },
      "source": [
        "# **Sentiment classification - close to the state of the art**\n",
        "\n",
        "Submitted By: Shaikh Muhammad Asjad Raza\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRAWuX_99gTI"
      },
      "source": [
        "This Notebook contains:\n",
        "1. Logistic Regression\n",
        "2. LSTM with GloVe Embeddding\n",
        "3. FastText Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSpel2LmH9Qw",
        "outputId": "eb2e656a-d03b-4a3d-8145-4dc5dffa7e4a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNiK1vPaImzC"
      },
      "source": [
        "# Import libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vk1rIBnYINuq"
      },
      "source": [
        "# **Load the data.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAH_lxCZIDu_"
      },
      "source": [
        "# read the data\n",
        "data = pd.read_pickle('/content/drive/MyDrive/data/data')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7phbMC4Igp-",
        "outputId": "171b5a05-d319-4cdd-8cc1-6021f46659ec"
      },
      "source": [
        "# Do the splitting\n",
        "train_df = data.iloc[0:25000, 1]\n",
        "y_train = data.iloc[0:25000, 0]\n",
        "valid_df = data.iloc[25000:, 1]\n",
        "y_valid = data.iloc[25000:, 0]\n",
        "print(train_df.shape, valid_df.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(25000,) (25000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQjpRjVjITiI"
      },
      "source": [
        "# **Models**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RwXFGKtUI7UZ"
      },
      "source": [
        "### **TFIDF for Logistic Regression**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwPNzlfrLNSP"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hE-f51EWJP-h"
      },
      "source": [
        "# Hyperparameters tuned according to the \n",
        "# creating bigrams\n",
        "tfidf = TfidfVectorizer(ngram_range = (1,4), sublinear_tf=True, max_features = 35000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6b67iVLiSUk8"
      },
      "source": [
        "train_tfidf = tfidf.fit_transform(train_df)\n",
        "valid_tfidf = tfidf.transform(valid_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdanyD_WTL4l",
        "outputId": "0c5d2d0b-8d2c-483a-acce-9dfeae3b35c6"
      },
      "source": [
        "vocab = tfidf.get_feature_names()\n",
        "print(\"Vocabulary length:\", len(vocab))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary length: 35000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qTc7CKgKTUCU",
        "outputId": "ad70e091-6ed8-40c1-e7d5-a39d6b2f72cf"
      },
      "source": [
        "print('Train dim:',train_tfidf.shape, 'valid dim:', valid_tfidf.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train dim: (25000, 35000) valid dim: (25000, 35000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ivjXw52T_iv"
      },
      "source": [
        "## **Logistic Regression**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZyJVl2pUEbd"
      },
      "source": [
        "# import necessary libraries\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylKmcx5XXTV_"
      },
      "source": [
        "# define stratified  k-fold Cross Validation\n",
        "kfold = StratifiedKFold(n_splits = 10, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVmI8_k_WD8e",
        "outputId": "0548d067-8ac2-43d9-f531-353d6b4aa3c9"
      },
      "source": [
        "lr = LogisticRegression(random_state = 19,  max_iter=200)\n",
        "\n",
        "# Hyperparameters choosen based on optimal performance\n",
        "lr_params = {\n",
        "    'penalty':['l2', 'l1'],\n",
        "    'C':[1],\n",
        "    'class_weight':[{1:1}],\n",
        "    'solver': ['liblinear']\n",
        "    }\n",
        "\n",
        "# Do the best parameter search using GridSerchCV\n",
        "lr_CV = GridSearchCV(lr, param_grid = [lr_params], cv = kfold, scoring = 'accuracy', n_jobs = 1, verbose = 1)\n",
        "lr_CV.fit(train_tfidf, y_train)\n",
        "print(lr_CV.best_params_)\n",
        "print(lr_CV.best_estimator_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 10 folds for each of 2 candidates, totalling 20 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:   11.2s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'C': 1, 'class_weight': {1: 1}, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "LogisticRegression(C=1, class_weight={1: 1}, dual=False, fit_intercept=True,\n",
            "                   intercept_scaling=1, l1_ratio=None, max_iter=200,\n",
            "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
            "                   random_state=19, solver='liblinear', tol=0.0001, verbose=0,\n",
            "                   warm_start=False)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HcrhVRjuX3vh",
        "outputId": "22723fb3-0316-47f2-9e5d-722146a4655c"
      },
      "source": [
        "# get the best score on train_tfidf\n",
        "print('Accuracy on Train set: ' + str(lr_CV.best_score_))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy on Train set: 0.8855999999999999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tga1HjYQYAec",
        "outputId": "4696e367-f559-4e87-a42e-08515c9081b2"
      },
      "source": [
        "# predict and check accuracy on valid_tfidf\n",
        "y_pred_valid = lr_CV.predict(valid_tfidf)\n",
        "print('Accuracy on Validation set: ' + str(accuracy_score(y_valid, y_pred_valid)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy on Validation set: 0.88116\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5GTGsvhfbiF"
      },
      "source": [
        "Observations:\n",
        "1. To my surprise, Logistic Regression turned out to be slightly better than LSTM with Keras/Golve Embedding.\n",
        "2. There was 1% increase in the validation accuracy when sublinear_tf was set to True. \n",
        "3. Reason could be that with High dimentional data Logictic Regression performs better because Model complexity can be controlled (less overfitting) whereas in case of LSTM model complexity is difficult to control which leads to overfitting. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FD7KXt2cIX60"
      },
      "source": [
        "## **LSTM with Global Vectors for Word Representation (GloVe) Embedding**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnKO8ktKR5oY"
      },
      "source": [
        "Using the following pretrained version:\n",
        "\n",
        "Wikipedia 2014 + Gigaword 5 (6B tokens, 400K vocab, uncased, 200 dimentional vectors)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lV4s6zHYIdrU"
      },
      "source": [
        "# Import the necessary libraries\n",
        "from tensorflow.keras.layers import LSTM, Input, Embedding, Dense, Dropout, SpatialDropout1D, Lambda\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import backend as be\n",
        "from tensorflow.keras.optimizers import Adadelta, Adam, SGD\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.initializers import glorot_normal\n",
        "from tensorflow.keras.models import load_model\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_DWNfNZItpe"
      },
      "source": [
        "# according to performance\n",
        "max_seq_length = 200\n",
        "max_words = 32000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMM6rsdsD6MG"
      },
      "source": [
        "# This function will Tokenize the data\n",
        "# Putting indexes of words in vocab in training/validation data to generate sequence of numbers\n",
        "# Then pad the sequence so that they are of same length as expected by LSTM\n",
        "\n",
        "def tokenize_padding_seq(train_df, valid_df, max_words, max_seq_length):\n",
        "   \n",
        "    tokenizer = Tokenizer(num_words=max_words, split=' ', lower=True)\n",
        "\n",
        "    tokenizer.fit_on_texts(train_df)\n",
        "    X_train = tokenizer.texts_to_sequences(train_df)\n",
        "    X_valid  = tokenizer.texts_to_sequences(valid_df)\n",
        "\n",
        "    X_train = sequence.pad_sequences(X_train, maxlen=max_seq_length, padding='post', truncating='post')\n",
        "    X_valid  = sequence.pad_sequences(X_valid,  maxlen=max_seq_length, padding='post', truncating='post')\n",
        "    \n",
        "    # Tokeneizer gives more tokens then that of the actual vocab size\n",
        "    word_index = tokenizer.word_index\n",
        "    print('Found %s unique tokens.' % len(word_index))\n",
        "    return X_train, y_train, X_valid, y_valid, word_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_pIFUEOD9Gp",
        "outputId": "d6b69ade-95bd-4378-c099-33dcd0f3db82"
      },
      "source": [
        "# call the tokenize_padding_seq \n",
        "X_train, y_train, X_valid, y_valid, word_index = tokenize_padding_seq(train_df, valid_df, max_words=max_words, max_seq_length=max_seq_length)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 31594 unique tokens.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DnzdXuVnV9DZ",
        "outputId": "5e0c4205-0810-4947-fcb4-77cb09649b18"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 200)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZO8cOHUStKW"
      },
      "source": [
        "#### **Generate Embedding matrix**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2H1rI73Ii2t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d14caf65-8ff7-4ef5-c7c4-b5a78b7f9906"
      },
      "source": [
        "# load the file and create embedding index\n",
        "\n",
        "# folder where glove embeddings are availabe\n",
        "glove_dir = '/content/drive/MyDrive/glove.6B' \n",
        "\n",
        "#create a dictionary for embedding vectors and words\n",
        "embedding_index = {}\n",
        "f = open(os.path.join(glove_dir, 'glove.6B.200d.txt'), encoding='utf8')\n",
        "\n",
        "# line by line read the file\n",
        "for line in f:\n",
        "  values = line.split()\n",
        "  # in our dictionary the key would be a word\n",
        "  # word is the 0th element in the file\n",
        "  word = values[0] \n",
        "  # get the corresponding vector  \n",
        "  coefs = np.asarray(values[1:], dtype='float32')\n",
        "  # put word and vector in the dictionary\n",
        "  embedding_index[word] = coefs\n",
        "# once done close the file\n",
        "f.close()\n",
        "print('Found %s word vectors.' %len(embedding_index))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 400000 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWCiGBJfIi5P"
      },
      "source": [
        "# As i am using 200 dimentional pretrained vector\n",
        "embedding_size = 200\n",
        "\n",
        "# create an array embeddings full of zeros with the following dimention\n",
        "# in the for loop i will populate it\n",
        "embedding_matrix = np.zeros((max_words, embedding_size))\n",
        "\n",
        "# for every word in vocab \n",
        "for word, i in word_index.items():\n",
        "  # only consider max_words\n",
        "  if i < max_words:\n",
        "    embedding_vector = embedding_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "      embedding_matrix[i] = embedding_vector "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MxTG0c6UbY4R",
        "outputId": "e7b3815f-c6f6-483a-cfdb-a895b21fc559"
      },
      "source": [
        "embedding_matrix.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32000, 200)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cw-AYNFnYtb6"
      },
      "source": [
        "#### **Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xAdJmW5THVa"
      },
      "source": [
        "# Define # of LSTM units\n",
        "LSTM_size = 64\n",
        "# Define dropout rate\n",
        "dropout_rate = 0.4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DH7hs-m2IjA3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73c2089d-cea5-414a-8b6d-4ee3b3ce8e0b"
      },
      "source": [
        "# reset the graph\n",
        "be.clear_session()\n",
        "tf.compat.v1.reset_default_graph()\n",
        "\n",
        "\n",
        "# Input layer \n",
        "inputs = Input(shape = (max_seq_length, ))\n",
        "\n",
        "# Embedding Layer\n",
        "# Trainable = False\n",
        "embedding_layer = Embedding(max_words, embedding_size, input_length=max_seq_length, weights=[embedding_matrix], mask_zero=True, trainable=False)(inputs)\n",
        "\n",
        "# LSTM Layer\n",
        "LSTM_1 = LSTM(LSTM_size, kernel_initializer=glorot_normal(seed=19), return_sequences=False)(embedding_layer)\n",
        "\n",
        "# Dropout\n",
        "Dropout_1 = Dropout(dropout_rate, seed=19)(LSTM_1)\n",
        "\n",
        "# Output layer\n",
        "# Binary Classification problem therefore 1 unit & sigmoid activation\n",
        "predictions = Dense(1, activation = 'sigmoid')(Dropout_1)\n",
        "\n",
        "# Initilize the Model\n",
        "model = Model(inputs=inputs, outputs=predictions)\n",
        "\n",
        "# Get the model summay\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 200)]             0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 200, 200)          6400000   \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 64)                67840     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 6,467,905\n",
            "Trainable params: 67,905\n",
            "Non-trainable params: 6,400,000\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZQoQ9SSw16M"
      },
      "source": [
        "#### **Loss and Optimization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztlGtbBPIjFx"
      },
      "source": [
        "# Loss, since its a binary classification problem\n",
        "loss = 'binary_crossentropy'\n",
        "\n",
        "# Optimizer\n",
        "optimizer = Adam(learning_rate=0.0001) \n",
        " \n",
        "# Compilation\n",
        "model.compile(loss=loss, optimizer= optimizer, metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjp1zNJwwtEy"
      },
      "source": [
        "#### **Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-WXw2O5Ii-L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e618b03-59db-4229-bf90-17377a016b42"
      },
      "source": [
        "checkpoint_filepath = '/content/drive/MyDrive/checkpoint_lstm_glove/temp'\n",
        "\n",
        "# Save the weights based on min validation loss. \n",
        "# even if model overfits i'll use this checkpoint to get the weights which had min valid loss.\n",
        "model_checkpoint_callback = ModelCheckpoint(filepath=checkpoint_filepath, save_weights_only=True, monitor='val_loss', mode='min', save_best_only=True)\n",
        "\n",
        "# I will use the entire train data for training and use the test data (which i renamed \n",
        "# as valid data) for validation.\n",
        "\n",
        "# Loads the weights (IF NEEDED)\n",
        "#model.load_weights(checkpoint_filepath)\n",
        "with tf.device('/gpu:0' and '/gpu:1'):\n",
        "  history = model.fit(X_train, \n",
        "                      y_train,\n",
        "                      epochs=20,\n",
        "                      validation_data=(X_valid, y_valid),\n",
        "                      batch_size=16,\n",
        "                      verbose=1,\n",
        "                      shuffle=True,\n",
        "                      callbacks=[model_checkpoint_callback])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "1563/1563 [==============================] - 26s 16ms/step - loss: 0.5318 - accuracy: 0.7240 - val_loss: 0.4384 - val_accuracy: 0.7992\n",
            "Epoch 2/20\n",
            "1563/1563 [==============================] - 25s 16ms/step - loss: 0.4308 - accuracy: 0.8096 - val_loss: 0.4250 - val_accuracy: 0.8039\n",
            "Epoch 3/20\n",
            "1563/1563 [==============================] - 25s 16ms/step - loss: 0.4018 - accuracy: 0.8238 - val_loss: 0.3930 - val_accuracy: 0.8253\n",
            "Epoch 4/20\n",
            "1563/1563 [==============================] - 25s 16ms/step - loss: 0.3834 - accuracy: 0.8360 - val_loss: 0.3793 - val_accuracy: 0.8329\n",
            "Epoch 5/20\n",
            "1563/1563 [==============================] - 25s 16ms/step - loss: 0.3687 - accuracy: 0.8425 - val_loss: 0.3985 - val_accuracy: 0.8206\n",
            "Epoch 6/20\n",
            "1563/1563 [==============================] - 25s 16ms/step - loss: 0.3551 - accuracy: 0.8486 - val_loss: 0.3937 - val_accuracy: 0.8272\n",
            "Epoch 7/20\n",
            "1563/1563 [==============================] - 25s 16ms/step - loss: 0.3434 - accuracy: 0.8551 - val_loss: 0.3554 - val_accuracy: 0.8488\n",
            "Epoch 8/20\n",
            "1563/1563 [==============================] - 25s 16ms/step - loss: 0.3329 - accuracy: 0.8612 - val_loss: 0.3451 - val_accuracy: 0.8530\n",
            "Epoch 9/20\n",
            "1563/1563 [==============================] - 25s 16ms/step - loss: 0.3214 - accuracy: 0.8670 - val_loss: 0.3459 - val_accuracy: 0.8548\n",
            "Epoch 10/20\n",
            "1563/1563 [==============================] - 25s 16ms/step - loss: 0.3106 - accuracy: 0.8719 - val_loss: 0.3412 - val_accuracy: 0.8550\n",
            "Epoch 11/20\n",
            "1563/1563 [==============================] - 25s 16ms/step - loss: 0.3065 - accuracy: 0.8745 - val_loss: 0.3692 - val_accuracy: 0.8460\n",
            "Epoch 12/20\n",
            "1563/1563 [==============================] - 25s 16ms/step - loss: 0.2973 - accuracy: 0.8782 - val_loss: 0.3382 - val_accuracy: 0.8598\n",
            "Epoch 13/20\n",
            "1563/1563 [==============================] - 25s 16ms/step - loss: 0.2894 - accuracy: 0.8825 - val_loss: 0.3464 - val_accuracy: 0.8546\n",
            "Epoch 14/20\n",
            "1563/1563 [==============================] - 25s 16ms/step - loss: 0.2848 - accuracy: 0.8838 - val_loss: 0.3638 - val_accuracy: 0.8466\n",
            "Epoch 15/20\n",
            "1563/1563 [==============================] - 25s 16ms/step - loss: 0.2749 - accuracy: 0.8899 - val_loss: 0.3327 - val_accuracy: 0.8604\n",
            "Epoch 16/20\n",
            "1563/1563 [==============================] - 26s 16ms/step - loss: 0.2703 - accuracy: 0.8918 - val_loss: 0.3319 - val_accuracy: 0.8616\n",
            "Epoch 17/20\n",
            "1563/1563 [==============================] - 25s 16ms/step - loss: 0.2629 - accuracy: 0.8954 - val_loss: 0.3529 - val_accuracy: 0.8485\n",
            "Epoch 18/20\n",
            "1563/1563 [==============================] - 25s 16ms/step - loss: 0.2567 - accuracy: 0.8982 - val_loss: 0.3350 - val_accuracy: 0.8619\n",
            "Epoch 19/20\n",
            "1563/1563 [==============================] - 25s 16ms/step - loss: 0.2530 - accuracy: 0.9016 - val_loss: 0.3460 - val_accuracy: 0.8608\n",
            "Epoch 20/20\n",
            "1563/1563 [==============================] - 26s 16ms/step - loss: 0.2442 - accuracy: 0.9040 - val_loss: 0.3447 - val_accuracy: 0.8556\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Qrksgm6kq2-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "fdcf7f27-aa57-4c00-acc7-16078b55ebf2"
      },
      "source": [
        "# Visualize the loss since i have several epochs in this Model:\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['loss'], label='train')\n",
        "plt.plot(history.history['val_loss'], label='test')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4LEK3Q0j40H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ccf460f-bd10-4d66-eb49-ebb4ee395243"
      },
      "source": [
        "model.load_weights(checkpoint_filepath)\n",
        "scores = model.evaluate(X_valid, y_valid, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "782/782 [==============================] - 5s 6ms/step - loss: 0.3319 - accuracy: 0.8616\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3SMosfOArUCi"
      },
      "source": [
        "Observations:\n",
        "1. Increasing the number of units/layers was only resulting in overfitting and dropout was not helping either.\n",
        "2. In my opinion, given the data preprocessing that i have done, the Model has reached the generalization capasity. \n",
        "3. Or, Getting more training data may help in this case (Since I have used 50% train and 50% Valid).  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFnw8BdUz6Rg"
      },
      "source": [
        "## **FastText Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ElB79vSvK3Pz",
        "outputId": "b07f2d29-8565-4987-f013-156b4461c9b2"
      },
      "source": [
        "# Download fasttext Model\n",
        "!wget https://github.com/facebookresearch/fastText/archive/v0.9.2.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-12-04 00:57:13--  https://github.com/facebookresearch/fastText/archive/v0.9.2.zip\n",
            "Resolving github.com (github.com)... 192.30.255.113\n",
            "Connecting to github.com (github.com)|192.30.255.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://codeload.github.com/facebookresearch/fastText/zip/v0.9.2 [following]\n",
            "--2020-12-04 00:57:13--  https://codeload.github.com/facebookresearch/fastText/zip/v0.9.2\n",
            "Resolving codeload.github.com (codeload.github.com)... 192.30.255.120\n",
            "Connecting to codeload.github.com (codeload.github.com)|192.30.255.120|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/zip]\n",
            "Saving to: v0.9.2.zip.2\n",
            "\n",
            "v0.9.2.zip.2            [  <=>               ]   4.17M  15.2MB/s    in 0.3s    \n",
            "\n",
            "2020-12-04 00:57:14 (15.2 MB/s) - v0.9.2.zip.2 saved [4369852]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtqSyD3DK3Xk"
      },
      "source": [
        "# unzip the files\n",
        "#!unzip v0.9.2.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dutoCoqDK3Zs",
        "outputId": "de4ffc53-51e1-4d60-a5a7-26c8c1d1374a"
      },
      "source": [
        "# Move to the fastText directory\n",
        "os.chdir('fastText-0.9.2')\n",
        "!make"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/args.cc\n",
            "c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/autotune.cc\n",
            "c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/matrix.cc\n",
            "c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/dictionary.cc\n",
            "c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/loss.cc\n",
            "c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/productquantizer.cc\n",
            "c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/densematrix.cc\n",
            "c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/quantmatrix.cc\n",
            "c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/vector.cc\n",
            "c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/model.cc\n",
            "c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/utils.cc\n",
            "c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/meter.cc\n",
            "c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/fasttext.cc\n",
            "c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG args.o autotune.o matrix.o dictionary.o loss.o productquantizer.o densematrix.o quantmatrix.o vector.o model.o utils.o meter.o fasttext.o src/main.cc -o fasttext\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4jlIJbSCXYV9",
        "outputId": "ca1ecfa3-cdf7-41bb-f7bf-f7420548a0f4"
      },
      "source": [
        "# install FastText Model\n",
        "!pip install fasttext"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: fasttext in /usr/local/lib/python3.6/dist-packages (0.9.2)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from fasttext) (50.3.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fasttext) (1.18.5)\n",
            "Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.6/dist-packages (from fasttext) (2.6.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwVTwTmiOWmy"
      },
      "source": [
        "#### **Data Preparation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evNcnzuHOi_X"
      },
      "source": [
        "According to FastText documentation: \n",
        "\n",
        "Each line of the text file contains a list of labels, followed by the corresponding document. All the labels start by the __label__ prefix, which is how fastText recognize what is a label or what is a word. The model is then trained to predict the labels given the word in the document."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ghMUfc5K3bz"
      },
      "source": [
        "# get the data\n",
        "data = pd.read_pickle('/content/drive/MyDrive/data/data')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOI9u-4oK3eW",
        "outputId": "9f6b76c2-9190-4815-df82-e1c8729e8cc0"
      },
      "source": [
        "# splitting\n",
        "train_df = data.iloc[0:25000, ]\n",
        "valid_df = data.iloc[25000:, ]\n",
        "print(train_df.shape, valid_df.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(25000, 2) (25000, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GhJMqRaK3k4"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# convert the labels from float to positive and negative labels\n",
        "train_df['label'] = train_df['label'].map({1.0: 'positive', 0.0: 'negative'})\n",
        "valid_df['label'] = valid_df['label'].map({1.0: 'positive', 0.0: 'negative'})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtZy0ON1RHJY"
      },
      "source": [
        "All the labels start by the label prefix, which is how fastText recognize what is a label or what is a word. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtkIKDn8RBBU"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "train_df['label'] = ['__label__' + str(l) for l in train_df['label']]\n",
        "valid_df['label'] = ['__label__' + str(l) for l in valid_df['label']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "quISRhDiSkMl"
      },
      "source": [
        "**For training the algorithm i have to specify the path as input. Input must be a filepath** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBE_UXUGR_Bi"
      },
      "source": [
        "# dataframe to csv\n",
        "train_df.to_csv(r'/content/drive/MyDrive/fast_text_data/train.txt', header=False, sep = ' ', index=False)\n",
        "valid_df.to_csv(r'/content/drive/MyDrive/fast_text_data/test.txt', header=False, sep = ' ', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tePrI-uHWC7S"
      },
      "source": [
        "### **Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pa0GvhmOXOBk"
      },
      "source": [
        "# import the model\n",
        "import fasttext"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_95TDtlMWCSn"
      },
      "source": [
        "# Training\n",
        "model = fasttext.train_supervised(input=\"/content/drive/MyDrive/fast_text_data/train.txt\", epoch=32, wordNgrams=3, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LgeWhnDQ8UHE",
        "outputId": "1a99cd24-c0ba-4fe6-b8e7-7abfbacb31e5"
      },
      "source": [
        "# Testing\n",
        "model.test('/content/drive/MyDrive/fast_text_data/test.txt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 0.87192, 0.87192)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1hSFa9zE2Ulf"
      },
      "source": [
        "Python version of the implementation did not print training and validation verbose. I am now trying command line tool:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNVEFMFDRZpO"
      },
      "source": [
        "### **Model try 2**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aq3NeVs9wFqD",
        "outputId": "e43f1231-dd5a-4f3a-aca4-e16c54892e5a"
      },
      "source": [
        "# Training\n",
        "!./fasttext supervised -input '/content/drive/MyDrive/fast_text_data/train.txt' -output model_sentiment -epoch 30 -wordNgrams 3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Read 2M words\n",
            "Number of words:  40214\n",
            "Number of labels: 2\n",
            "Progress: 100.0% words/sec/thread:  119414 lr:  0.000000 avg.loss:  0.092667 ETA:   0h 0m 0s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3rsHE5ExHNQ"
      },
      "source": [
        "OUTPUT:  \n",
        "(P@1) ----->  precision\n",
        "\n",
        "(R@1) -----> recall  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzIB0DIwwvbj",
        "outputId": "80737ffa-7441-4fd1-94f7-d76d175b97b2"
      },
      "source": [
        "# Testing\n",
        "!./fasttext test model_sentiment.bin '/content/drive/MyDrive/fast_text_data/test.txt'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "N\t25000\n",
            "P@1\t0.872\n",
            "R@1\t0.872\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nh35CIEz8fXy"
      },
      "source": [
        "**Well Both are giving the same results. Lets try to predict a few sentences:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vh2Zhefg8x14",
        "outputId": "ab8083fe-ae5f-4e71-edb0-5879adc80c13"
      },
      "source": [
        "# Testing on actual reviews from imdb website (not from the test/valid/train set). \n",
        "\n",
        "Test_list = [\n",
        "             # review 0: Actual user rating 10/10\n",
        "             \"This film is every definition of the word 'impeccable.' Scorcese's fantastic storytelling ability mixed with phenomenal acting from DiCaprio, Hill and the rest of the cast makes for an awesome combination. The film is never boring and gives you a glimpse into the life of a man who had everything in the world only to have it taken away.\",\n",
        "             # review 1: Actual user rating 10/10\n",
        "             '\"The Wolf of Wall Street\" is infectiously entertaining. It is probably the funniest movie I have seen all year with witty dialogue, over the top characters, and filled with energy that bleeds off the screen. Between all the fun however,  there is also a story about addiction and how it can cause a downward spiral in your life whether it be drugs, money, or power.',\n",
        "             # review 2: Actual user rating 10/10\n",
        "             \"For anyone who isn't much into cinema, I would recommend watching Django Unchained and you will fall in love with films forever.This film is a classic western full of drama, suspense and tension with a tremendously unpredictable plot but with a sense of realism taken into consideration.I believe it would be hard to dislike this masterpiece as it has it all: action, adventure and even a sense of romance and the occasional humour.\",\n",
        "             # review 3: Actual user rating 1/10\n",
        "             \"Critics are giving Tarantino way too much credit for saying anything meaningful in this film. His references to 60's spaghetti westerns or 70's black exploitation films don't go beyond cheesy film titles and the interpolation of icky songs on the sound track - the social relevance of these films could hardly matter to him; he doesn't have much to say about slavery, other than it was bad; his emotional palette ranges from revenge to more revenge - anything else is beyond him; his lengthy dialog scenes are becoming predictable -dull, too-cute. The only real difference between the films Tarantino is emulating and his film is a fetish for mixing violence with comedy. I can't help but think that Tarantino sees himself as a liberal-cool-auteur-artist; but it is pretty easy to see through what critics call his social 'deepening' as a recent tendency to patronize\",\n",
        "             # review 4: Actual user rating 1/10\n",
        "             \"This is nominated for best picture? You got to be kidding me. Where are the sweeping themes, the original ideas, the unique contribution to cinema? This is just a remake of a spaghetti western/blaxploitation movie, with the same old funky soundtrack, the same old movie homages, plot tricks, blood splatter, etc. It was fresh and original in Pulp Fiction, but half a dozen movies later, it is becoming formula. But, wait, I forgot, this is a savage indictment of slavery. Hahahaha. This is movie nerd Tarantino stealing other directors' ideas and painting the world in ludicrously simplistic black-and-white, in Technicolor, so that the bad guys are so detestable you'll cheer graphic violence and mass murder. This time it was slavers, last time it was Nazis, what clich bad guys will be next? Terrorists? Vampires? In a musical homage? How long can this juvenile director keep spinning the same old blood-spattered revenge theme in a genre remake? This is not cutting edge cinema, folks. Using the N-word does not make you a daring film genius. Now if Quentin spent his multi-million budgets on a movie about, say, a father whose daughter was gunned down in a mass shooting, and goes on a killing spree at the NRA headquarters or a Hollywood studio, I'd be just as disgusted but at least I'd call him original. Well, no, it would be just more twisted clich, like all Tarantino movies these days.\",\n",
        "             # review 5: Actual user rating 5/10\n",
        "             \"A bounty hunter helps a slave rescue his wife. Tarantino has a sick obsession with violence. In films like 'Pulp Fiction' and 'Inglorious Basterds,' the scripts are so interesting that one can overlook the blood-fest. Unfortunately, the script for this Western is so long and dreary that the repellent violence can't be ignored. The film actually gets off to a fairly engaging start, thanks to a gem of a performance from Waltz as dentist slash bounty hunter. Foxx is much less interesting as Django, a perpetually angry and arrogant slave. Things take a turn for the dreary when DiCaprio enters the picture as an evil slave owner. Soon thereafter the film runs out of steam but still rambles on for about an hour.\",\n",
        "             # review 6: Actual user rating 4/10\n",
        "             \"Perversely, this movie would actually have to be better for me to dislike it. As it is, it's just too boring to care about. Good cast and crew, likeable production values, no complaints there - but there's also no story, no believability, no suspense, no interest, no ANYTHING.\",\n",
        "             # review 7: Actual user rating 3/10 (The interesting one!)\n",
        "             \"Spielberg/ Decaprio/Hanks - just those three names alone are enticing enough to get viewers into cinemas to watch this film, based on true life events.I can't fault this film. It's entertaining, it's well performed and well directed (of course!), but it just didn't grab me in the same way my favourite films do. Perhaps I found it hard to root for a character who is clearly breaking the law, I don't know.I would recommend it though, because it's a pacy, fun film that is entertaining enough.\",\n",
        "             # review 8: Actual user rating 3/10 \n",
        "             \"I cannot believe what I am reading. Sorting reviews by most helpful, they are mostly giving the movie 10/10. Did we watch something different? This movie contains almost no character development. I seriously can't even remember their names by this point.Also, the cliches with the stories were plentiful. The CGI was overdone and the entire movie leaves the audience feeling detached from reality. Seriously, give this one a pass. By far the wort Jurassic movie.\",\n",
        "             # review 9: Actual user rating 5/10\n",
        "             \"Ever saw those monster movies on Syfy channel? You know, the ones with the 2 dimensional characters. That have poor dialogue and horrible special effects. Well that's Jurassic World, with exception of the sfx. Jurassic World looks expensive, has some fantastic shots but unfortunately nobody seemed to care about writing interesting characters or story lines. And if the characters are so badly written it's not surprisingly that the actor's deliver poor work. Yes, the movie has a few funny moments but the entire cast is uninteresting, shallow and predictable. Basically just like the storyline.\"\n",
        "             ]\n",
        "\n",
        "for i in range(len(Test_list)):\n",
        "  print(\"'review %d' prediction:  \" %i + str(model.predict(Test_list[i], k=1)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'review 0' prediction:  (('__label__positive',), array([0.98248661]))\n",
            "'review 1' prediction:  (('__label__positive',), array([0.98123014]))\n",
            "'review 2' prediction:  (('__label__positive',), array([0.90841728]))\n",
            "'review 3' prediction:  (('__label__negative',), array([0.80000019]))\n",
            "'review 4' prediction:  (('__label__negative',), array([0.52201205]))\n",
            "'review 5' prediction:  (('__label__negative',), array([0.81545871]))\n",
            "'review 6' prediction:  (('__label__negative',), array([0.98961776]))\n",
            "'review 7' prediction:  (('__label__positive',), array([0.89246422]))\n",
            "'review 8' prediction:  (('__label__negative',), array([0.948093]))\n",
            "'review 9' prediction:  (('__label__negative',), array([0.99948269]))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9miTl8lSlqz"
      },
      "source": [
        "\"review 0\" prediction:  ('__label__positive',), array([**0.98248661**]) ---> means with 98% probability review 0 belongs to negative class."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f15QYRaA1iws"
      },
      "source": [
        "Observations:\n",
        "1. WordNgrams=3 really helped in improving the results.\n",
        "2. Model tends to overfit after 30 epochs. \n",
        "3. Easy to implement and performs considerably good."
      ]
    }
  ]
}